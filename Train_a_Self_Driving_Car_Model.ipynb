{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train a Self Driving Car Model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gigerbytes/simulate_a_self_driving_car/blob/master/Train_a_Self_Driving_Car_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TutIrsSxuyz7",
        "colab_type": "text"
      },
      "source": [
        "# Simulate a self driving car\n",
        "\n",
        "This code trains a model that can be used to simulate a self driving car through Udacity's open-sourced [Self Driving Car Simulator.](https://github.com/udacity/self-driving-car-sim)\n",
        "\n",
        "The notebook was ported from [Siraj Raval's How to Simulate a Self Driving Car repository](https://github.com/llSourcell/How_to_simulate_a_self_driving_car\n",
        ") to make developing and editing the model easier.\n",
        "\n",
        "## Instructions\n",
        "Just upload your `data` folder as a .zip file into colab and run the notebook!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqNPE1plw7jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utils - Load Helper functions\n",
        "import cv2, os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
        "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        "\n",
        "\n",
        "def load_image(data_dir, image_file):\n",
        "    \"\"\"\n",
        "    Load RGB images from a file\n",
        "    \"\"\"\n",
        "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
        "\n",
        "\n",
        "def crop(image):\n",
        "    \"\"\"\n",
        "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
        "    \"\"\"\n",
        "    return image[60:-25, :, :] # remove the sky and the car front\n",
        "\n",
        "\n",
        "def resize(image):\n",
        "    \"\"\"\n",
        "    Resize the image to the input shape used by the network model\n",
        "    \"\"\"\n",
        "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "def rgb2yuv(image):\n",
        "    \"\"\"\n",
        "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "\n",
        "def preprocess(image):\n",
        "    \"\"\"\n",
        "    Combine all preprocess functions into one\n",
        "    \"\"\"\n",
        "    image = crop(image)\n",
        "    image = resize(image)\n",
        "    image = rgb2yuv(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def choose_image(data_dir, center, left, right, steering_angle):\n",
        "    \"\"\"\n",
        "    Randomly choose an image from the center, left or right, and adjust\n",
        "    the steering angle.\n",
        "    \"\"\"\n",
        "    choice = np.random.choice(3)\n",
        "    if choice == 0:\n",
        "        return load_image(data_dir, left), steering_angle + 0.2\n",
        "    elif choice == 1:\n",
        "        return load_image(data_dir, right), steering_angle - 0.2\n",
        "    return load_image(data_dir, center), steering_angle\n",
        "\n",
        "\n",
        "def random_flip(image, steering_angle):\n",
        "    \"\"\"\n",
        "    Randomly flipt the image left <-> right, and adjust the steering angle.\n",
        "    \"\"\"\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = cv2.flip(image, 1)\n",
        "        steering_angle = -steering_angle\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def random_translate(image, steering_angle, range_x, range_y):\n",
        "    \"\"\"\n",
        "    Randomly shift the image virtially and horizontally (translation).\n",
        "    \"\"\"\n",
        "    trans_x = range_x * (np.random.rand() - 0.5)\n",
        "    trans_y = range_y * (np.random.rand() - 0.5)\n",
        "    steering_angle += trans_x * 0.002\n",
        "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
        "    height, width = image.shape[:2]\n",
        "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def random_shadow(image):\n",
        "    \"\"\"\n",
        "    Generates and adds random shadow\n",
        "    \"\"\"\n",
        "    # (x1, y1) and (x2, y2) forms a line\n",
        "    # xm, ym gives all the locations of the image\n",
        "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
        "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
        "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
        "\n",
        "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
        "    # Our coordinate is up side down.  So, the above the line:\n",
        "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
        "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
        "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
        "    mask = np.zeros_like(image[:, :, 1])\n",
        "    mask[np.where((ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0)] = 1\n",
        "\n",
        "    # choose which side should have shadow and adjust saturation\n",
        "    cond = mask == np.random.randint(2)\n",
        "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
        "\n",
        "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
        "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
        "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
        "\n",
        "\n",
        "def random_brightness(image):\n",
        "    \"\"\"\n",
        "    Randomly adjust brightness of the image.\n",
        "    \"\"\"\n",
        "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
        "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "\n",
        "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
        "    \"\"\"\n",
        "    Generate an augumented image and adjust steering angle.\n",
        "    (The steering angle is associated with the center image)\n",
        "    \"\"\"\n",
        "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
        "    image, steering_angle = random_flip(image, steering_angle)\n",
        "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
        "    image = random_shadow(image)\n",
        "    image = random_brightness(image)\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
        "    \"\"\"\n",
        "    Generate training image give image paths and associated steering angles\n",
        "    \"\"\"\n",
        "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
        "    steers = np.empty(batch_size)\n",
        "    while True:\n",
        "        i = 0\n",
        "        for index in np.random.permutation(image_paths.shape[0]):\n",
        "            center, left, right = image_paths[index]\n",
        "            steering_angle = steering_angles[index]\n",
        "            # argumentation\n",
        "            if is_training and np.random.rand() < 0.6:\n",
        "                image, steering_angle = augument(data_dir, center, left, right, steering_angle)\n",
        "            else:\n",
        "                image = load_image(data_dir, center)\n",
        "            # add the image and steering angle to the batch\n",
        "            images[i] = preprocess(image)\n",
        "            steers[i] = steering_angle\n",
        "            i += 1\n",
        "            if i == batch_size:\n",
        "                break\n",
        "        yield images, steers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZjuNOEr1pse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # data analysis toolkit - create, read, update, delete datasets\n",
        "import numpy as np #matrix math\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split #to split out training and testing data \n",
        "#keras is a high level wrapper on top of tensorflow (machine learning library)\n",
        "#The Sequential container is a linear stack of layers\n",
        "from keras.models import Sequential\n",
        "#popular optimization strategy that uses gradient descent \n",
        "from keras.optimizers import Adam\n",
        "#to save our model periodically as checkpoints for loading later\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "#what types of layers do we want our model to have?\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "import argparse\n",
        "#for reading files\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUOt8qYa_kFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA2G0FdJ8iqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def load_data(args):\n",
        "    \"\"\"\n",
        "    Load training data and split it into training and validation set\n",
        "    \"\"\"\n",
        "    #reads CSV file into a single dataframe variable\n",
        "    data_df = pd.read_csv(os.path.join(os.getcwd(), args['data_dir'], 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "\n",
        "    #yay dataframes, we can select rows and columns by their names\n",
        "    #we'll store the camera images as our input data\n",
        "    X = data_df[['center', 'left', 'right']].values\n",
        "    #and our steering commands as our output data\n",
        "    y = data_df['steering'].values\n",
        "\n",
        "    #now we can split the data into a training (80), testing(20), and validation set\n",
        "    #thanks scikit learn\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args['test_size'], random_state=0)\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_sVnxcg8u8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_model(args):\n",
        "    \"\"\"\n",
        "    NVIDIA model used\n",
        "    Image normalization to avoid saturation and make gradients work better.\n",
        "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Drop out (0.5)\n",
        "    Fully connected: neurons: 100, activation: ELU\n",
        "    Fully connected: neurons: 50, activation: ELU\n",
        "    Fully connected: neurons: 10, activation: ELU\n",
        "    Fully connected: neurons: 1 (output)\n",
        "\n",
        "    # the convolution layers are meant to handle feature engineering\n",
        "    the fully connected layer for predicting the steering angle.\n",
        "    dropout avoids overfitting\n",
        "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. \n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
        "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
        "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
        "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
        "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
        "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
        "    model.add(Dropout(args['keep_prob']))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='elu'))\n",
        "    model.add(Dense(50, activation='elu'))\n",
        "    model.add(Dense(10, activation='elu'))\n",
        "    model.add(Dense(1))\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXARkvdZ8vWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_model(model, args, X_train, X_valid, y_train, y_valid):\n",
        "    \"\"\"\n",
        "    Train the model\n",
        "    \"\"\"\n",
        "    #Saves the model after every epoch.\n",
        "    #quantity to monitor, verbosity i.e logging mode (0 or 1), \n",
        "    #if save_best_only is true the latest best model according to the quantity monitored will not be overwritten.\n",
        "    #mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is\n",
        "    # made based on either the maximization or the minimization of the monitored quantity. For val_acc, \n",
        "    #this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically\n",
        "    # inferred from the name of the monitored quantity.\n",
        "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
        "                                 monitor='val_loss',\n",
        "                                 verbose=0,\n",
        "                                 save_best_only=args['save_best_only'],\n",
        "                                 mode='auto')\n",
        "\n",
        "    #calculate the difference between expected steering angle and actual steering angle\n",
        "    #square the difference\n",
        "    #add up all those differences for as many data points as we have\n",
        "    #divide by the number of them\n",
        "    #that value is our mean squared error! this is what we want to minimize via\n",
        "    #gradient descent\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=args['learning_rate']))\n",
        "\n",
        "    #Fits the model on data generated batch-by-batch by a Python generator.\n",
        "\n",
        "    #The generator is run in parallel to the model, for efficiency. \n",
        "    #For instance, this allows you to do real-time data augmentation on images on CPU in \n",
        "    #parallel to training your model on GPU.\n",
        "    #so we reshape our data into their appropriate batches and train our model simulatenously\n",
        "    model.fit_generator(batch_generator(args['data_dir'], X_train, y_train, args['batch_size'], True),\n",
        "                        args['samples_per_epoch'],\n",
        "                        args['nb_epoch'],\n",
        "                        max_q_size=1,\n",
        "                        validation_data=batch_generator(args['data_dir'], X_valid, y_valid, args['batch_size'], False),\n",
        "                        nb_val_samples=len(X_valid),\n",
        "                        callbacks=[checkpoint],\n",
        "                        verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVvEhJt88w0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#for command line args\n",
        "def s2b(s):\n",
        "    \"\"\"\n",
        "    Converts a string to boolean value\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    return s == 'true' or s == 'yes' or s == 'y' or s == '1'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O12_hIk68yLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "    print(sess)\n",
        "  \n",
        "    args = {\n",
        "      \"test_size\":0.2,\n",
        "      \"keep_prob\":0.5,\n",
        "      \"nb_epoch\":1,\n",
        "      \"samples_per_epoch\" : 20000,\n",
        "      \"batch_size\": 50,\n",
        "      \"save_best_only\": 'true',\n",
        "      \"learning_rate\": 1.0e-3,\n",
        "      \"data_dir\":\"data\"\n",
        "    }\n",
        "    \n",
        "    \n",
        "    #print parameters\n",
        "    print('-' * 30)\n",
        "    print('Parameters')\n",
        "    print('-' * 30)\n",
        "    for key, value in args.items():\n",
        "        print('{:<20} := {}'.format(key, value))\n",
        "    print('-' * 30)\n",
        "\n",
        "    #load data\n",
        "    data = load_data(args)\n",
        "    #build model\n",
        "    model = build_model(args)\n",
        "    #train model on data, it saves as model.h5 \n",
        "    train_model(model, args, *data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kesgyQJB8zyi",
        "colab_type": "code",
        "outputId": "e940c147-b807-4215-bfed-8bc1fbd6e208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.client.session.Session object at 0x7f1c7ec20a90>\n",
            "------------------------------\n",
            "Parameters\n",
            "------------------------------\n",
            "test_size            := 0.2\n",
            "keep_prob            := 0.5\n",
            "nb_epoch             := 1\n",
            "samples_per_epoch    := 20000\n",
            "batch_size           := 50\n",
            "save_best_only       := true\n",
            "learning_rate        := 0.001\n",
            "data_dir             := data\n",
            "------------------------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_1 (Lambda)            (None, 66, 200, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 18, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 252,219\n",
            "Trainable params: 252,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 20000, 1, validation_data=<generator..., callbacks=[<keras.ca..., verbose=1, validation_steps=301, max_queue_size=1)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 2071/20000 [==>...........................] - ETA: 2:44:44 - loss: 0.0342"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}